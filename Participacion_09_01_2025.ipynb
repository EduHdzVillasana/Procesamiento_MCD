{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyWjeWA7k19xroQjrU5nG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EduHdzVillasana/Procesamiento_MCD/blob/main/Participacion_09_01_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W7j4_9mBNmU3"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/raduangelescu/gutenbergpy\n",
        "!pip install gutenbergpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8ZUu4f9Odfc",
        "outputId": "ed3874fe-2481-4a4a-c44f-dd7c4551ec61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gutenbergpy\n",
            "  Downloading gutenbergpy-0.3.5-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from gutenbergpy) (1.0.0)\n",
            "Collecting httpsproxy-urllib2 (from gutenbergpy)\n",
            "  Downloading httpsproxy_urllib2-1.0.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from gutenbergpy) (5.3.0)\n",
            "Collecting pymongo (from gutenbergpy)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from gutenbergpy) (75.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from gutenbergpy) (5.2.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->gutenbergpy)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading gutenbergpy-0.3.5-py3-none-any.whl (22 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: httpsproxy-urllib2\n",
            "  Building wheel for httpsproxy-urllib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httpsproxy-urllib2: filename=httpsproxy_urllib2-1.0-py3-none-any.whl size=29250 sha256=b1c05fd0316d0829a159b0a23eb0a17884bfa1b3c4c2d8e5578f76f85f2834d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/fa/c3/4c14e72101070c40b56c2bfb4617e510e68f121e4f736a5d2a\n",
            "Successfully built httpsproxy-urllib2\n",
            "Installing collected packages: httpsproxy-urllib2, dnspython, pymongo, gutenbergpy\n",
            "Successfully installed dnspython-2.7.0 gutenbergpy-0.3.5 httpsproxy-urllib2-1.0 pymongo-4.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gutenbergpy import textget"
      ],
      "metadata": {
        "id": "-Mq9l8aKOP5w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_libro(id = 2701):\n",
        "    raw_book = textget.get_text_by_id(id) # with headers\n",
        "    clean_book = textget.strip_headers(raw_book) # without headers\n",
        "    return clean_book, raw_book"
      ],
      "metadata": {
        "id": "cIXfa_C4Ogm2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens(text):\n",
        "    texto_limpio = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(texto_limpio)\n",
        "    texto_filtrado = [word for word in tokens if word not in stop_words]\n",
        "    return texto_filtrado"
      ],
      "metadata": {
        "id": "ia370CvVP1vr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_frequencies(tokens):\n",
        "    stemmer = PorterStemmer()\n",
        "    processed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    frequencies = Counter(processed_tokens)\n",
        "    return frequencies"
      ],
      "metadata": {
        "id": "oSko4gqyP4MU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai5l0WB6P_lY",
        "outputId": "dfaebb90-b9d2-4bd5-d661-cbefa8d86083"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text, raw_text = obtener_libro()\n",
        "str_libro = clean_text.decode()\n",
        "list_libro = str_libro.split(\"\\n\")\n",
        "filter_libro = list(filter(None, list_libro))\n",
        "map_libro = list(map(tokens, filter_libro))"
      ],
      "metadata": {
        "id": "VJrle1XcQEWu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "for token in map_libro:\n",
        "    tokens.extend(token)"
      ],
      "metadata": {
        "id": "iiKV6oHdTMs4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_stem = analyze_frequencies(tokens)"
      ],
      "metadata": {
        "id": "WqzKCwnsSeaO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFrecuencias con STEM:\")\n",
        "for word, freq in freq_stem.most_common(10):\n",
        "    print(f\"{word}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNbhpjDNTVtT",
        "outputId": "b1fd2217-f99e-4640-f761-905dcc93ecec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Frecuencias con STEM:\n",
            "whale: 1461\n",
            "one: 920\n",
            "like: 589\n",
            "upon: 565\n",
            "ship: 556\n",
            "man: 499\n",
            "ahab: 493\n",
            "ye: 485\n",
            "sea: 466\n",
            "seem: 459\n"
          ]
        }
      ]
    }
  ]
}